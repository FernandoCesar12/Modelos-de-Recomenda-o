{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "674eff94",
   "metadata": {},
   "source": [
    "# Entrando com as informações de acesso ao servidor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9c1f655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotar a frequencia de cursos por usuário\n",
    "# EVG pegar a tabela tb_tematica_curso\n",
    "# Pedir acesso a base da EVG (perfil de usuario no lugar da siape)\n",
    "# Descrição do curso em variáveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07097fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# Entrando com os pacotes necessários \n",
    "\n",
    "import pandas as pd # manipula os dados em DataFrame\n",
    "import psycopg2 # conecta o banco sql ao python\n",
    "import pandas.io.sql as sqlio # importa os dados do banco sql em formato Dataframe\n",
    "\n",
    "# Colocando as informações de login no servidor\n",
    "\n",
    "host = '10.224.9.157'\n",
    "dbname= 'dw_consolidado' \n",
    "username = 'postgres' \n",
    "password = 'Enap@123' \n",
    "\n",
    "# Realizando a coneção com o banco de dados\n",
    "\n",
    "conn = psycopg2.connect(host = host, dbname = dbname, user = username, password = password, port='5432')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4097ff",
   "metadata": {},
   "source": [
    "# Importando as bases de dados "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58c2d135",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ferna\\anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Puxando o banco de dados\n",
    "\n",
    "sql = f\"select desc_curso, modalidade_acao, categoria_acao, curso from tb_fato_matricula inner join dim_aluno using (dim_aluno_id) inner join dim_origem_dado using (dim_origem_dado_id) inner join dim_acao using (dim_acao_id) inner join dim_situacao using (dim_situacao_id) left join tb_fato_indicadores using (id_fato_matricula) left join dim_avaliacao using (dim_avaliacao_id) where (formato_acao = 'Curso') order by data_conclusao asc;\"\n",
    "df_acao = sqlio.read_sql_query(sql, conn) # Pegando as tabelas de interesse "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50fdb2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removendo duplicadas de curso com preferência para aqueles onde a descrição não é um campo nulo\n",
    "\n",
    "df_acao = df_acao.drop_duplicates(subset=['curso'], keep='last') # Removendo duplicadas de cursos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2fba2a",
   "metadata": {},
   "source": [
    "# Modelo número 1: Cosine Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f95a46",
   "metadata": {},
   "source": [
    "## Realizando a limpeza dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3552f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ferna\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ferna\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Pegando apenas as colunas de interesse\n",
    "\n",
    "df_acao = df_acao[[\"desc_curso\", \"modalidade_acao\" , \"categoria_acao\",\"curso\"]]\n",
    "\n",
    "df_acao = df_acao.reset_index()\n",
    "del df_acao['index']\n",
    "\n",
    "# Seria interessante colocarmos um filtro de modalidade para o usuário \n",
    "\n",
    "'''\n",
    "modalidade = ['Remota','A Distância']\n",
    "df_acao_filtrado = df_acao[df_acao['modalidade_acao'].isin(modalidade)]\n",
    "'''\n",
    "\n",
    "df_acao_filtrado = df_acao\n",
    "\n",
    "def clean_data(x):\n",
    "    if isinstance(x, list):\n",
    "        return [str.lower(i.replace('  ', ' ')) for i in x]\n",
    "    else:\n",
    "        if isinstance(x, str):\n",
    "            return str.lower(x.replace('  ', ' '))\n",
    "        else:\n",
    "            return ''\n",
    " \n",
    "features = [\"desc_curso\", \"modalidade_acao\" , \"categoria_acao\",\"curso\"]\n",
    "\n",
    "for f in features:\n",
    "    df_acao_filtrado[f] = df_acao_filtrado[f].apply(clean_data)\n",
    "    \n",
    "# Criando uma única coluna com todos os dados\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def create_soup(data):\n",
    "    return data[\"curso\"]+\" \"+ data[\"desc_curso\"]+\" \"+ data[\"categoria_acao\"]+\" \"+ data[\"modalidade_acao\"]\n",
    "\n",
    "df_acao_filtrado['soup'] = create_soup(df_acao_filtrado)\n",
    "\n",
    "# Removendo caracteres repetidos\n",
    "\n",
    "import re \n",
    "\n",
    "def cleaning_repeating_char(text):\n",
    "    return re.sub(r'(.)1+', r'1', text)\n",
    "\n",
    "df_acao_filtrado['soup'] = df_acao_filtrado['soup'].astype(str).apply(lambda x: cleaning_repeating_char(x))\n",
    "\n",
    "# Removendo valores numéricos\n",
    "\n",
    "def cleaning_numbers(data):\n",
    "    return re.sub('[0-9]+', '', data)\n",
    "\n",
    "df_acao_filtrado['soup'] = df_acao_filtrado['soup'].apply(lambda x: cleaning_numbers(x))\n",
    "\n",
    "#  Removendo Emoticons \n",
    "\n",
    "df_acao_filtrado['soup'] = df_acao_filtrado['soup'].astype(str).apply(lambda x: x.encode('latin-1', 'ignore').decode('latin-1'))\n",
    "\n",
    "# Removendo os stopwords\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words('portuguese')\n",
    "\n",
    "df_acao_filtrado['soup'] = df_acao_filtrado['soup'].astype(str).apply(lambda x: ' '.join([word for word in x.split() if word not in (stopwords)]))\n",
    "\n",
    "# Removendo acentuações\n",
    "\n",
    "textlist = df_acao_filtrado['soup'].astype(str).values.tolist()\n",
    "\n",
    "def traducao():\n",
    "    string_origem = 'ãÃâÂáÁàÀêÊéÉèÈîÎíÍìÌïÏõÕôÔóÓòÒûÛúÚùÙüÜçÇñÑ'\n",
    "    string_destino ='AAAAAAAAEEEEEEIIIIIIIIOOOOOOOOUUUUUUUUCCNN'\n",
    "    string_anulada ='`´_-¿?.:ª°º,\";()*/\\n' + \"\\\\\" + \"'\" + '\\t' \n",
    "    return string_origem.maketrans(string_origem, string_destino, string_anulada)\n",
    "\n",
    "for i in range(0,len(textlist)):\n",
    "    textlist[i] = textlist[i].translate(traducao()).lower()\n",
    "    \n",
    "df_acao_filtrado['soup'] = textlist\n",
    "\n",
    "# Aplicando o stemming\n",
    "\n",
    "st = nltk.PorterStemmer()\n",
    "\n",
    "def stemming_on_text(data):\n",
    "    text = [st.stem(word) for word in data]\n",
    "    return data\n",
    "\n",
    "df_acao_filtrado['soup']= df_acao_filtrado['soup'].apply(lambda x: stemming_on_text(x))\n",
    "\n",
    "# Aplicando o Lemmatizer\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "\n",
    "lm = nltk.WordNetLemmatizer()\n",
    "\n",
    "def lemmatizer_on_text(data):\n",
    "    text = [lm.lemmatize(word) for word in data]\n",
    "    return data\n",
    "\n",
    "df_acao_filtrado['soup'] = df_acao_filtrado['soup'].apply(lambda x: lemmatizer_on_text(x))\n",
    "\n",
    "# Serve para contar a frequência das palavras e alocar em uma matrix 2D\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "count_vectorizer = CountVectorizer()\n",
    "count_matrix = count_vectorizer.fit_transform(df_acao_filtrado[\"soup\"])\n",
    "\n",
    "# Modalidade de cálculo das distâncias \n",
    "\n",
    "cosine_sim2 = cosine_similarity(count_matrix, count_matrix) \n",
    "\n",
    "df_acao_filtrado = df_acao_filtrado.reset_index()\n",
    "indices = pd.Series(df_acao_filtrado.index, index=df_acao_filtrado['curso'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1425560c",
   "metadata": {},
   "source": [
    "## Realizando a previsão dos cursos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f77fb0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "microeconomia\n",
      "\n",
      "[254            macroeconomia\n",
      "554              estatística\n",
      "458    matemática financeira\n",
      "Name: curso, dtype: object]\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "def get_recommendations(title, cosine_sim=cosine_sim2):\n",
    "    \n",
    "    # Pega o índice do curso em interesse\n",
    "    idx = indices[title]\n",
    "\n",
    "    # Compara os scores com o curso base\n",
    "    \n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "\n",
    "    # Ordena os scores\n",
    "    \n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Separa os top 10 cursos (pula primeira linha pois o próprio filme é aquele mais correlacionado com ele mesmo)\n",
    "    sim_scores = sim_scores[1:4]\n",
    "\n",
    "    # Separa os indices dos cursos\n",
    "    movie_indices = [i[0] for i in sim_scores]\n",
    "\n",
    "    # Retorna os valores dos top 10 cursos calculados\n",
    "    \n",
    "    recomendacao = []\n",
    "    \n",
    "    recomendacao.append(df_acao_filtrado['curso'].iloc[movie_indices])\n",
    "    \n",
    "    return recomendacao\n",
    "\n",
    "\n",
    "print(\"microeconomia\")\n",
    "print()\n",
    "print(get_recommendations(\"microeconomia\", cosine_sim2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e6c462",
   "metadata": {},
   "source": [
    "## Realizando a previsão dos cursos (base cheia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c46911e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recomendacao 1</th>\n",
       "      <th>Recomendacao 2</th>\n",
       "      <th>Recomendacao 3</th>\n",
       "      <th>Curso</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dw aduaneiro</td>\n",
       "      <td>contencioso aduaneiro e tributário no âmbito da receita federal</td>\n",
       "      <td>reuniões produtivas</td>\n",
       "      <td>fiscalização aduaneira: conceitos aplicados pela receita federal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>instrumentos de planejamento: ppa, ldo e loa</td>\n",
       "      <td>reorganização societária, blindagem patrimonial e responsabilidade para a receita federal</td>\n",
       "      <td>o arrolamento de bens para a proteção do crédito tributário no âmbito da receita federal</td>\n",
       "      <td>planejamento sucessório e tributário aplicado à receita federal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>conceitos essenciais para avaliação socioeconômica de projetos</td>\n",
       "      <td>estatística</td>\n",
       "      <td>matemática financeira</td>\n",
       "      <td>oficina programa avaliação socioeconômica de projetos (asp)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>transferências da união: visão geral</td>\n",
       "      <td>termo de compromisso: atos preparatórios</td>\n",
       "      <td>validação do relatório de melhoria da gestão das transferências da união</td>\n",
       "      <td>transferências especiais</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>operação de drones no âmbito da receita federal</td>\n",
       "      <td>noções introdutórias de licitação e contratos administrativos</td>\n",
       "      <td>siafi básico</td>\n",
       "      <td>atendimento pré-hospitalar em acidentes com armas de fogo aplicado à receita federal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>noções introdutórias de licitação e contratos administrativos</td>\n",
       "      <td>siafi básico</td>\n",
       "      <td>formação de pregoeiros - teoria</td>\n",
       "      <td>curso básico de licitações - enfrentando (e vencendo) tabus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>a construção dos livros didáticos do pnld</td>\n",
       "      <td>materiais didáticos do pnld para o novo ensino médio</td>\n",
       "      <td>pnld literário</td>\n",
       "      <td>pnld – programa nacional do livro e do material didático</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>liderança e gestão de equipes</td>\n",
       "      <td>noções básicas do trabalho remoto</td>\n",
       "      <td>estruturas de gestão pública</td>\n",
       "      <td>a liderança pública em tempos de crise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>ações inovadoras da cgu</td>\n",
       "      <td>formação de conteudistas para cursos virtuais - módulo 1</td>\n",
       "      <td>formação de facilitadores de aprendizagem</td>\n",
       "      <td>solução pacífica de conflitos no âmbito da administração pública</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>orçamento público: elaboração e execução</td>\n",
       "      <td>introdução à orçamentação de obras rodoviárias</td>\n",
       "      <td>s2id - m3 - usuário estadual - acompanhamento das obras de reconstrução</td>\n",
       "      <td>fiscalização de projetos e obras de engenharia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>564 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      Recomendacao 1  \\\n",
       "0                                                       dw aduaneiro   \n",
       "1                       instrumentos de planejamento: ppa, ldo e loa   \n",
       "2     conceitos essenciais para avaliação socioeconômica de projetos   \n",
       "3                               transferências da união: visão geral   \n",
       "4                    operação de drones no âmbito da receita federal   \n",
       "..                                                               ...   \n",
       "559    noções introdutórias de licitação e contratos administrativos   \n",
       "560                        a construção dos livros didáticos do pnld   \n",
       "561                                    liderança e gestão de equipes   \n",
       "562                                          ações inovadoras da cgu   \n",
       "563                         orçamento público: elaboração e execução   \n",
       "\n",
       "                                                                                Recomendacao 2  \\\n",
       "0                              contencioso aduaneiro e tributário no âmbito da receita federal   \n",
       "1    reorganização societária, blindagem patrimonial e responsabilidade para a receita federal   \n",
       "2                                                                                  estatística   \n",
       "3                                                     termo de compromisso: atos preparatórios   \n",
       "4                                noções introdutórias de licitação e contratos administrativos   \n",
       "..                                                                                         ...   \n",
       "559                                                                               siafi básico   \n",
       "560                                       materiais didáticos do pnld para o novo ensino médio   \n",
       "561                                                          noções básicas do trabalho remoto   \n",
       "562                                   formação de conteudistas para cursos virtuais - módulo 1   \n",
       "563                                             introdução à orçamentação de obras rodoviárias   \n",
       "\n",
       "                                                                               Recomendacao 3  \\\n",
       "0                                                                         reuniões produtivas   \n",
       "1    o arrolamento de bens para a proteção do crédito tributário no âmbito da receita federal   \n",
       "2                                                                       matemática financeira   \n",
       "3                    validação do relatório de melhoria da gestão das transferências da união   \n",
       "4                                                                                siafi básico   \n",
       "..                                                                                        ...   \n",
       "559                                                           formação de pregoeiros - teoria   \n",
       "560                                                                            pnld literário   \n",
       "561                                                              estruturas de gestão pública   \n",
       "562                                                 formação de facilitadores de aprendizagem   \n",
       "563                   s2id - m3 - usuário estadual - acompanhamento das obras de reconstrução   \n",
       "\n",
       "                                                                                    Curso  \n",
       "0                        fiscalização aduaneira: conceitos aplicados pela receita federal  \n",
       "1                         planejamento sucessório e tributário aplicado à receita federal  \n",
       "2                             oficina programa avaliação socioeconômica de projetos (asp)  \n",
       "3                                                                transferências especiais  \n",
       "4    atendimento pré-hospitalar em acidentes com armas de fogo aplicado à receita federal  \n",
       "..                                                                                    ...  \n",
       "559                           curso básico de licitações - enfrentando (e vencendo) tabus  \n",
       "560                              pnld – programa nacional do livro e do material didático  \n",
       "561                                                a liderança pública em tempos de crise  \n",
       "562                      solução pacífica de conflitos no âmbito da administração pública  \n",
       "563                                        fiscalização de projetos e obras de engenharia  \n",
       "\n",
       "[564 rows x 4 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Sistema de recomendação automatico da base\n",
    "\n",
    "recomendacao_coisine = []\n",
    "curso_coisine = []\n",
    "\n",
    "for i in range(0,len(df_acao)):\n",
    "    try:\n",
    "        recomendacao_coisine.append(str(get_recommendations(df_acao['curso'][i], cosine_sim2)).replace('[','').replace(']','').split('\\n'))\n",
    "        curso_coisine.append(df_acao['curso'][i])\n",
    "    except:\n",
    "        pass\n",
    "  \n",
    "### Transformando em Dataframe\n",
    "\n",
    "Coisine_indicacao = pd.DataFrame(recomendacao_coisine ,columns=['Recomendacao 1','Recomendacao 2','Recomendacao 3','Recomendacao 4'])\n",
    "Coisine_indicacao['Curso'] = curso_coisine      \n",
    "del Coisine_indicacao['Recomendacao 4']\n",
    "\n",
    "\n",
    "for i in range(0,len(Coisine_indicacao)):\n",
    "    if '  ' in str(Coisine_indicacao['Recomendacao 1'][i]):\n",
    "       Coisine_indicacao['Recomendacao 1'][i] = str(Coisine_indicacao['Recomendacao 1'][i]).split('  ')[-1] \n",
    "    \n",
    "    \n",
    "for i in range(0,len(Coisine_indicacao)):\n",
    "    if '  ' in str(Coisine_indicacao['Recomendacao 2'][i]):\n",
    "       Coisine_indicacao['Recomendacao 2'][i] = str(Coisine_indicacao['Recomendacao 2'][i]).split('  ')[-1]\n",
    "    \n",
    "    \n",
    "for i in range(0,len(Coisine_indicacao)):\n",
    "    if '  ' in str(Coisine_indicacao['Recomendacao 3'][i]):\n",
    "       Coisine_indicacao['Recomendacao 3'][i] = str(Coisine_indicacao['Recomendacao 3'][i]).split('  ')[-1]\n",
    "    \n",
    "    \n",
    "### Exportando em formato csv\n",
    "\n",
    "Coisine_indicacao.to_csv(\"Coisine_indicacao.csv\", index=False, encoding='utf-8-sig', sep = '|')\n",
    "\n",
    "Coisine_indicacao"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a9f2c0",
   "metadata": {},
   "source": [
    "# Modelo número 2: LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d0c94c",
   "metadata": {},
   "source": [
    "## Realizando a limpeza dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b30e5da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ferna\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Download and installation successful\n",
      "You can now load the package via spacy.load('pt_core_news_sm')\n",
      "Score de Coerência:  0.3203319165818728\n"
     ]
    }
   ],
   "source": [
    "# Importing modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "\n",
    "# LDA Model\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "import gensim.corpora as corpora\n",
    "from pprint import pprint\n",
    "from gensim.models import CoherenceModel\n",
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Import the wordcloud library\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# Visualize the topics\n",
    "import pyLDAvis.gensim\n",
    "import pickle \n",
    "import pyLDAvis\n",
    "\n",
    "# Pegando apenas as colunas de interesse\n",
    "\n",
    "features = [\"desc_curso\", \"modalidade_acao\" , \"categoria_acao\", \"curso\"]\n",
    "df_acao = df_acao[features]\n",
    "\n",
    "df_acao.drop_duplicates(subset=['curso'], keep='last')\n",
    "\n",
    "df_acao = df_acao.reset_index()\n",
    "del df_acao['index']\n",
    "\n",
    "# Seria interessante colocarmos um filtro de modalidade para o usuário \n",
    "\n",
    "'''\n",
    "modalidade = ['Remota','A Distância']\n",
    "df_acao_filtrado = df_acao[df_acao['modalidade_acao'].isin(modalidade)]\n",
    "'''\n",
    "df_acao_filtrado = df_acao\n",
    "\n",
    "# Criando uma única coluna com todos os dados\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def create_soup(data):\n",
    "    return data[\"curso\"]+\" \"+ data[\"desc_curso\"]+\" \"+ data[\"categoria_acao\"]+\" \"+ data[\"modalidade_acao\"]\n",
    "\n",
    "df_acao_filtrado['soup'] = create_soup(df_acao_filtrado)\n",
    "\n",
    "# Tokenizando \n",
    "\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))\n",
    "    \n",
    "data_words = list(sent_to_words(df_acao_filtrado['soup']))\n",
    "df_acao_filtrado['Tokens'] = data_words\n",
    "\n",
    "# Removendo valores numéricos\n",
    "\n",
    "for i in range(0,len(df_acao_filtrado)):\n",
    "    \n",
    "    df_acao_filtrado['Tokens'][i] = re.sub('[0-9]+', '', str(df_acao_filtrado['Tokens'][i]))\n",
    "    \n",
    "#  Removendo Emoticons \n",
    "\n",
    "df_acao_filtrado['Tokens'] = df_acao_filtrado['Tokens'].astype(str).apply(lambda x: x.encode('latin-1', 'ignore').decode('latin-1'))\n",
    "\n",
    "# Removendo os stopwords\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words('portuguese')\n",
    "\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stopwords] for doc in texts]\n",
    "\n",
    "# Removendo acentuações\n",
    "\n",
    "teste = []\n",
    "def traducao():\n",
    "    string_origem = 'ãÃâÂáÁàÀêÊéÉèÈîÎíÍìÌïÏõÕôÔóÓòÒûÛúÚùÙüÜçÇñÑ'\n",
    "    string_destino ='AAAAAAAAEEEEEEIIIIIIIIOOOOOOOOUUUUUUUUCCNN'\n",
    "    string_anulada ='`´_-¿?.:ª°º\";()*/\\n][' + \"\\\\\" + \"'\" + '\\t' \n",
    "    return string_origem.maketrans(string_origem, string_destino, string_anulada)\n",
    "\n",
    "for i in range(0,len(df_acao_filtrado['Tokens'])):\n",
    "    df_acao_filtrado['Tokens'][i] = str(df_acao_filtrado['Tokens'][i]).translate(traducao()).lower()\n",
    "\n",
    "# Bigram\n",
    "\n",
    "bigram = gensim.models.Phrases(df_acao_filtrado['Tokens'], min_count=5, threshold=10) \n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "\n",
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "# Lemmatizer\n",
    "\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out\n",
    "\n",
    "import spacy \n",
    "\n",
    "spacy.cli.download(\"pt_core_news_sm\")\n",
    "\n",
    "# Removendo stopwords\n",
    "\n",
    "data_words_nostops = remove_stopwords(df_acao_filtrado['Tokens'])\n",
    "\n",
    "# Bigramas\n",
    "\n",
    "data_words_bigrams = make_bigrams(data_words_nostops)\n",
    "\n",
    "nlp = spacy.load(\"pt_core_news_sm\", disable=['parser', 'ner'])\n",
    "\n",
    "# Lematização\n",
    "\n",
    "data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
    "\n",
    "# Criando um dicionario\n",
    "\n",
    "id2word = corpora.Dictionary(data_lemmatized)\n",
    "\n",
    "id2word.filter_extremes(no_below=2, no_above=0.9)\n",
    "\n",
    "# Criando o corpus\n",
    "\n",
    "texts = data_lemmatized\n",
    "\n",
    "# Pegando as frequencias\n",
    "\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "# Estruturando o modelo\n",
    "\n",
    "lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
    " id2word=id2word,\n",
    " num_topics=15, \n",
    " random_state=100,\n",
    " chunksize=100,\n",
    " passes=10,\n",
    " alpha=0.01,\n",
    " eta=0.9)\n",
    "\n",
    "# Avaliando o score de coerência\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "\n",
    "print('Score de Coerência: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23654c60",
   "metadata": {},
   "source": [
    "## Criando uma base de scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eab836f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ferna\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>556</th>\n",
       "      <th>557</th>\n",
       "      <th>558</th>\n",
       "      <th>559</th>\n",
       "      <th>560</th>\n",
       "      <th>561</th>\n",
       "      <th>562</th>\n",
       "      <th>563</th>\n",
       "      <th>564</th>\n",
       "      <th>565</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.128004</td>\n",
       "      <td>0.048002</td>\n",
       "      <td>0.078762</td>\n",
       "      <td>0.150643</td>\n",
       "      <td>0.308429</td>\n",
       "      <td>0.236286</td>\n",
       "      <td>0.111149</td>\n",
       "      <td>0.166759</td>\n",
       "      <td>0.104770</td>\n",
       "      <td>...</td>\n",
       "      <td>0.068079</td>\n",
       "      <td>0.071842</td>\n",
       "      <td>0.094234</td>\n",
       "      <td>0.088983</td>\n",
       "      <td>0.073817</td>\n",
       "      <td>0.124124</td>\n",
       "      <td>0.062062</td>\n",
       "      <td>0.066704</td>\n",
       "      <td>0.114309</td>\n",
       "      <td>0.074901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.128004</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.046881</td>\n",
       "      <td>0.163028</td>\n",
       "      <td>0.161985</td>\n",
       "      <td>0.171896</td>\n",
       "      <td>0.091886</td>\n",
       "      <td>0.099258</td>\n",
       "      <td>0.207870</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027015</td>\n",
       "      <td>0.071270</td>\n",
       "      <td>0.040064</td>\n",
       "      <td>0.039233</td>\n",
       "      <td>0.029292</td>\n",
       "      <td>0.092351</td>\n",
       "      <td>0.076960</td>\n",
       "      <td>0.033086</td>\n",
       "      <td>0.070874</td>\n",
       "      <td>0.018576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.048002</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.046881</td>\n",
       "      <td>0.040757</td>\n",
       "      <td>0.053995</td>\n",
       "      <td>0.046881</td>\n",
       "      <td>0.055132</td>\n",
       "      <td>0.049629</td>\n",
       "      <td>0.044544</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040522</td>\n",
       "      <td>0.106904</td>\n",
       "      <td>0.080128</td>\n",
       "      <td>0.029424</td>\n",
       "      <td>0.043937</td>\n",
       "      <td>0.046176</td>\n",
       "      <td>0.184703</td>\n",
       "      <td>0.049629</td>\n",
       "      <td>0.085049</td>\n",
       "      <td>0.167183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.078762</td>\n",
       "      <td>0.046881</td>\n",
       "      <td>0.046881</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.120375</td>\n",
       "      <td>0.070877</td>\n",
       "      <td>0.061538</td>\n",
       "      <td>0.090462</td>\n",
       "      <td>0.065146</td>\n",
       "      <td>0.043853</td>\n",
       "      <td>...</td>\n",
       "      <td>0.053192</td>\n",
       "      <td>0.087706</td>\n",
       "      <td>0.039443</td>\n",
       "      <td>0.067593</td>\n",
       "      <td>0.028837</td>\n",
       "      <td>0.166686</td>\n",
       "      <td>0.121226</td>\n",
       "      <td>0.032573</td>\n",
       "      <td>0.027910</td>\n",
       "      <td>0.036576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.150643</td>\n",
       "      <td>0.163028</td>\n",
       "      <td>0.040757</td>\n",
       "      <td>0.120375</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.154047</td>\n",
       "      <td>0.147125</td>\n",
       "      <td>0.173019</td>\n",
       "      <td>0.169910</td>\n",
       "      <td>0.088957</td>\n",
       "      <td>...</td>\n",
       "      <td>0.080926</td>\n",
       "      <td>0.106749</td>\n",
       "      <td>0.057151</td>\n",
       "      <td>0.083948</td>\n",
       "      <td>0.050141</td>\n",
       "      <td>0.223956</td>\n",
       "      <td>0.197608</td>\n",
       "      <td>0.056637</td>\n",
       "      <td>0.060661</td>\n",
       "      <td>0.031798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>0.124124</td>\n",
       "      <td>0.092351</td>\n",
       "      <td>0.046176</td>\n",
       "      <td>0.166686</td>\n",
       "      <td>0.223956</td>\n",
       "      <td>0.104717</td>\n",
       "      <td>0.060613</td>\n",
       "      <td>0.106921</td>\n",
       "      <td>0.112291</td>\n",
       "      <td>0.071989</td>\n",
       "      <td>...</td>\n",
       "      <td>0.078588</td>\n",
       "      <td>0.103664</td>\n",
       "      <td>0.155399</td>\n",
       "      <td>0.095109</td>\n",
       "      <td>0.071010</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.164179</td>\n",
       "      <td>0.064167</td>\n",
       "      <td>0.109961</td>\n",
       "      <td>0.036026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>0.062062</td>\n",
       "      <td>0.076960</td>\n",
       "      <td>0.184703</td>\n",
       "      <td>0.121226</td>\n",
       "      <td>0.197608</td>\n",
       "      <td>0.087264</td>\n",
       "      <td>0.060613</td>\n",
       "      <td>0.142562</td>\n",
       "      <td>0.112291</td>\n",
       "      <td>0.043193</td>\n",
       "      <td>...</td>\n",
       "      <td>0.065490</td>\n",
       "      <td>0.069109</td>\n",
       "      <td>0.090650</td>\n",
       "      <td>0.057065</td>\n",
       "      <td>0.085211</td>\n",
       "      <td>0.164179</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.048125</td>\n",
       "      <td>0.151197</td>\n",
       "      <td>0.108077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>0.066704</td>\n",
       "      <td>0.033086</td>\n",
       "      <td>0.049629</td>\n",
       "      <td>0.032573</td>\n",
       "      <td>0.056637</td>\n",
       "      <td>0.056274</td>\n",
       "      <td>0.048860</td>\n",
       "      <td>0.057459</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.046424</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056310</td>\n",
       "      <td>0.074278</td>\n",
       "      <td>0.069592</td>\n",
       "      <td>0.051111</td>\n",
       "      <td>0.091584</td>\n",
       "      <td>0.064167</td>\n",
       "      <td>0.048125</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.132958</td>\n",
       "      <td>0.038720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>0.114309</td>\n",
       "      <td>0.070874</td>\n",
       "      <td>0.085049</td>\n",
       "      <td>0.027910</td>\n",
       "      <td>0.060661</td>\n",
       "      <td>0.112509</td>\n",
       "      <td>0.111640</td>\n",
       "      <td>0.114878</td>\n",
       "      <td>0.088639</td>\n",
       "      <td>0.066296</td>\n",
       "      <td>...</td>\n",
       "      <td>0.072373</td>\n",
       "      <td>0.095467</td>\n",
       "      <td>0.107333</td>\n",
       "      <td>0.096347</td>\n",
       "      <td>0.078473</td>\n",
       "      <td>0.109961</td>\n",
       "      <td>0.151197</td>\n",
       "      <td>0.132958</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.033177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>0.074901</td>\n",
       "      <td>0.018576</td>\n",
       "      <td>0.167183</td>\n",
       "      <td>0.036576</td>\n",
       "      <td>0.031798</td>\n",
       "      <td>0.126379</td>\n",
       "      <td>0.109728</td>\n",
       "      <td>0.064520</td>\n",
       "      <td>0.058080</td>\n",
       "      <td>0.034752</td>\n",
       "      <td>...</td>\n",
       "      <td>0.047422</td>\n",
       "      <td>0.041703</td>\n",
       "      <td>0.062515</td>\n",
       "      <td>0.022957</td>\n",
       "      <td>0.034280</td>\n",
       "      <td>0.036026</td>\n",
       "      <td>0.108077</td>\n",
       "      <td>0.038720</td>\n",
       "      <td>0.033177</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>566 rows × 566 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6    \\\n",
       "0    1.000000  0.128004  0.048002  0.078762  0.150643  0.308429  0.236286   \n",
       "1    0.128004  1.000000  0.047619  0.046881  0.163028  0.161985  0.171896   \n",
       "2    0.048002  0.047619  1.000000  0.046881  0.040757  0.053995  0.046881   \n",
       "3    0.078762  0.046881  0.046881  1.000000  0.120375  0.070877  0.061538   \n",
       "4    0.150643  0.163028  0.040757  0.120375  1.000000  0.154047  0.147125   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "561  0.124124  0.092351  0.046176  0.166686  0.223956  0.104717  0.060613   \n",
       "562  0.062062  0.076960  0.184703  0.121226  0.197608  0.087264  0.060613   \n",
       "563  0.066704  0.033086  0.049629  0.032573  0.056637  0.056274  0.048860   \n",
       "564  0.114309  0.070874  0.085049  0.027910  0.060661  0.112509  0.111640   \n",
       "565  0.074901  0.018576  0.167183  0.036576  0.031798  0.126379  0.109728   \n",
       "\n",
       "          7         8         9    ...       556       557       558  \\\n",
       "0    0.111149  0.166759  0.104770  ...  0.068079  0.071842  0.094234   \n",
       "1    0.091886  0.099258  0.207870  ...  0.027015  0.071270  0.040064   \n",
       "2    0.055132  0.049629  0.044544  ...  0.040522  0.106904  0.080128   \n",
       "3    0.090462  0.065146  0.043853  ...  0.053192  0.087706  0.039443   \n",
       "4    0.173019  0.169910  0.088957  ...  0.080926  0.106749  0.057151   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "561  0.106921  0.112291  0.071989  ...  0.078588  0.103664  0.155399   \n",
       "562  0.142562  0.112291  0.043193  ...  0.065490  0.069109  0.090650   \n",
       "563  0.057459  0.068966  0.046424  ...  0.056310  0.074278  0.069592   \n",
       "564  0.114878  0.088639  0.066296  ...  0.072373  0.095467  0.107333   \n",
       "565  0.064520  0.058080  0.034752  ...  0.047422  0.041703  0.062515   \n",
       "\n",
       "          559       560       561       562       563       564       565  \n",
       "0    0.088983  0.073817  0.124124  0.062062  0.066704  0.114309  0.074901  \n",
       "1    0.039233  0.029292  0.092351  0.076960  0.033086  0.070874  0.018576  \n",
       "2    0.029424  0.043937  0.046176  0.184703  0.049629  0.085049  0.167183  \n",
       "3    0.067593  0.028837  0.166686  0.121226  0.032573  0.027910  0.036576  \n",
       "4    0.083948  0.050141  0.223956  0.197608  0.056637  0.060661  0.031798  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "561  0.095109  0.071010  1.000000  0.164179  0.064167  0.109961  0.036026  \n",
       "562  0.057065  0.085211  0.164179  1.000000  0.048125  0.151197  0.108077  \n",
       "563  0.051111  0.091584  0.064167  0.048125  1.000000  0.132958  0.038720  \n",
       "564  0.096347  0.078473  0.109961  0.151197  0.132958  1.000000  0.033177  \n",
       "565  0.022957  0.034280  0.036026  0.108077  0.038720  0.033177  1.000000  \n",
       "\n",
       "[566 rows x 566 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removendo os stopwords\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words('portuguese')\n",
    "\n",
    "df_acao_filtrado['soup'] = df_acao_filtrado['soup'].astype(str).apply(lambda x: ' '.join([word for word in x.split() if word not in (stopwords)]))\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "count_vectorizer = CountVectorizer()\n",
    "sparse_matrix = count_vectorizer.fit_transform(df_acao_filtrado[\"soup\"])\n",
    "\n",
    "\n",
    "# Convertendo uma matriz sparsa em DataFrame Pandas\n",
    "\n",
    "doc_term_matrix = sparse_matrix.todense()\n",
    "matrix_df = pd.DataFrame(doc_term_matrix, \n",
    "                  columns=count_vectorizer.get_feature_names(), index=df_acao_filtrado.index)\n",
    "\n",
    "similarity_scores = cosine_similarity(sparse_matrix, sparse_matrix) \n",
    "\n",
    "scores_df = pd.DataFrame(similarity_scores )\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4549b6",
   "metadata": {},
   "source": [
    "## Realizando a previsão dos cursos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e4ac9bcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<gensim.interfaces.TransformedCorpus object at 0x000001D56819AEB0>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['estatística',\n",
       " 'matemática financeira',\n",
       " 'conceitos essenciais para avaliação socioeconômica de projetos']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def Sort_Tuple(tup):  \n",
    "    return(sorted(tup, key = lambda x: x[1], reverse = True))   \n",
    "\n",
    "doc_num, topic_num, prob = [], [], []\n",
    "print(lda_model.get_document_topics(corpus))\n",
    "\n",
    "for n in range(len(df_acao)):\n",
    "    get_document_topics = lda_model.get_document_topics(corpus[n])\n",
    "    doc_num.append(n)\n",
    "    sorted_doc_topics = Sort_Tuple(get_document_topics)\n",
    "    topic_num.append(sorted_doc_topics[0][0])\n",
    "    prob.append(sorted_doc_topics[0][1])\n",
    "    \n",
    "df_acao['Doc'] = doc_num\n",
    "df_acao['Topic'] = topic_num\n",
    "df_acao['Probability'] = prob\n",
    "\n",
    "def recommend(title,scores_df, df):\n",
    "    recommended = []\n",
    "    \n",
    "    # getting title's index \n",
    "    title = title.lower()\n",
    "    df['curso'] = df['curso'].str.lower()\n",
    "    index = df[df['curso']==title].index[0]\n",
    "    \n",
    "    top10_list = list(scores_df.iloc[index].sort_values(ascending = False).iloc[1:30].index)\n",
    "    \n",
    "    for each in top10_list:\n",
    "        recommended.append(df.iloc[each].curso)\n",
    "    \n",
    "    recommended = list(dict.fromkeys(recommended))\n",
    "    \n",
    "    return recommended[1:4]\n",
    "\n",
    "recommend(\"microeconomia\",scores_df, df_acao)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38485cc",
   "metadata": {},
   "source": [
    "## Realizando a previsão dos cursos (base cheia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4ab649dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recomendacao 1</th>\n",
       "      <th>Recomendacao 2</th>\n",
       "      <th>Recomendacao 3</th>\n",
       "      <th>Curso</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dw aduaneiro</td>\n",
       "      <td>reuniões produtivas</td>\n",
       "      <td>contabilidade com foco na gestão do orçamento público</td>\n",
       "      <td>fiscalização aduaneira: conceitos aplicados pela receita federal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>reorganização societária, blindagem patrimonial e responsabilidade para a receita federal</td>\n",
       "      <td>o arrolamento de bens para a proteção do crédito tributário no âmbito da receita federal</td>\n",
       "      <td>representação fiscal para fins penais no âmbito da receita federal</td>\n",
       "      <td>planejamento sucessório e tributário aplicado à receita federal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>estatística</td>\n",
       "      <td>matemática financeira</td>\n",
       "      <td>programa de gestão em projetos urbanos: curso iv - projetos no âmbito do programa de minha casa, minha vida</td>\n",
       "      <td>oficina programa avaliação socioeconômica de projetos (asp)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>termo de compromisso: atos preparatórios</td>\n",
       "      <td>validação do relatório de melhoria da gestão das transferências da união</td>\n",
       "      <td>plano de melhoria da gestão das transferências da união</td>\n",
       "      <td>transferências especiais</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>noções introdutórias de licitação e contratos administrativos</td>\n",
       "      <td>siafi básico</td>\n",
       "      <td>direitos dos imigrantes e orientações para o atendimento</td>\n",
       "      <td>atendimento pré-hospitalar em acidentes com armas de fogo aplicado à receita federal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>siafi básico</td>\n",
       "      <td>formação de pregoeiros - teoria</td>\n",
       "      <td>impactos da mudança do clima para a gestão municipal</td>\n",
       "      <td>curso básico de licitações - enfrentando (e vencendo) tabus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>materiais didáticos do pnld para o novo ensino médio</td>\n",
       "      <td>pnld literário</td>\n",
       "      <td>a importância do pnld</td>\n",
       "      <td>pnld – programa nacional do livro e do material didático</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>noções básicas do trabalho remoto</td>\n",
       "      <td>estruturas de gestão pública</td>\n",
       "      <td>gestão em ouvidoria</td>\n",
       "      <td>a liderança pública em tempos de crise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>formação de conteudistas para cursos virtuais - módulo 1</td>\n",
       "      <td>formação de facilitadores de aprendizagem</td>\n",
       "      <td>estruturas de gestão pública</td>\n",
       "      <td>solução pacífica de conflitos no âmbito da administração pública</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>introdução à orçamentação de obras rodoviárias</td>\n",
       "      <td>obras públicas de edificação e de saneamento - módulo planejamento</td>\n",
       "      <td>gestão de direitos no processo de financiamento de projetos audiovisuais com recursos públicos</td>\n",
       "      <td>fiscalização de projetos e obras de engenharia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>566 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                Recomendacao 1  \\\n",
       "0                                                                                 dw aduaneiro   \n",
       "1    reorganização societária, blindagem patrimonial e responsabilidade para a receita federal   \n",
       "2                                                                                  estatística   \n",
       "3                                                     termo de compromisso: atos preparatórios   \n",
       "4                                noções introdutórias de licitação e contratos administrativos   \n",
       "..                                                                                         ...   \n",
       "561                                                                               siafi básico   \n",
       "562                                       materiais didáticos do pnld para o novo ensino médio   \n",
       "563                                                          noções básicas do trabalho remoto   \n",
       "564                                   formação de conteudistas para cursos virtuais - módulo 1   \n",
       "565                                             introdução à orçamentação de obras rodoviárias   \n",
       "\n",
       "                                                                               Recomendacao 2  \\\n",
       "0                                                                         reuniões produtivas   \n",
       "1    o arrolamento de bens para a proteção do crédito tributário no âmbito da receita federal   \n",
       "2                                                                       matemática financeira   \n",
       "3                    validação do relatório de melhoria da gestão das transferências da união   \n",
       "4                                                                                siafi básico   \n",
       "..                                                                                        ...   \n",
       "561                                                           formação de pregoeiros - teoria   \n",
       "562                                                                            pnld literário   \n",
       "563                                                              estruturas de gestão pública   \n",
       "564                                                 formação de facilitadores de aprendizagem   \n",
       "565                        obras públicas de edificação e de saneamento - módulo planejamento   \n",
       "\n",
       "                                                                                                  Recomendacao 3  \\\n",
       "0                                                          contabilidade com foco na gestão do orçamento público   \n",
       "1                                             representação fiscal para fins penais no âmbito da receita federal   \n",
       "2    programa de gestão em projetos urbanos: curso iv - projetos no âmbito do programa de minha casa, minha vida   \n",
       "3                                                        plano de melhoria da gestão das transferências da união   \n",
       "4                                                       direitos dos imigrantes e orientações para o atendimento   \n",
       "..                                                                                                           ...   \n",
       "561                                                         impactos da mudança do clima para a gestão municipal   \n",
       "562                                                                                        a importância do pnld   \n",
       "563                                                                                          gestão em ouvidoria   \n",
       "564                                                                                 estruturas de gestão pública   \n",
       "565               gestão de direitos no processo de financiamento de projetos audiovisuais com recursos públicos   \n",
       "\n",
       "                                                                                    Curso  \n",
       "0                        fiscalização aduaneira: conceitos aplicados pela receita federal  \n",
       "1                         planejamento sucessório e tributário aplicado à receita federal  \n",
       "2                             oficina programa avaliação socioeconômica de projetos (asp)  \n",
       "3                                                                transferências especiais  \n",
       "4    atendimento pré-hospitalar em acidentes com armas de fogo aplicado à receita federal  \n",
       "..                                                                                    ...  \n",
       "561                           curso básico de licitações - enfrentando (e vencendo) tabus  \n",
       "562                              pnld – programa nacional do livro e do material didático  \n",
       "563                                                a liderança pública em tempos de crise  \n",
       "564                      solução pacífica de conflitos no âmbito da administração pública  \n",
       "565                                        fiscalização de projetos e obras de engenharia  \n",
       "\n",
       "[566 rows x 4 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Sistema de recomendação automatico da base\n",
    "\n",
    "recomendacao_LDA = []\n",
    "curso_LDA = []\n",
    "\n",
    "for i in range(0,len(df_acao)):\n",
    "    try:\n",
    "        if len(recommend(df_acao['curso'][i],scores_df, df_acao)) != 0:\n",
    "            recomendacao_LDA.append(recommend(df_acao['curso'][i],scores_df, df_acao))\n",
    "            curso_LDA.append(df_acao['curso'][i])\n",
    "    except:\n",
    "        pass\n",
    "  \n",
    "### Transformando em Dataframe\n",
    "\n",
    "LDA_indicacao = pd.DataFrame(recomendacao_LDA ,columns=['Recomendacao 1','Recomendacao 2', 'Recomendacao 3'])\n",
    "LDA_indicacao['Curso'] = curso_LDA      \n",
    "\n",
    "### Exportando em formato csv\n",
    "\n",
    "LDA_indicacao.to_csv(\"LDA_indicacao.csv\", index=False, encoding='utf-8-sig', sep = '|')\n",
    "\n",
    "LDA_indicacao"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
